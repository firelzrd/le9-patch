From 181beef5b287a90c061ce70ad46514b730e0de71 Mon Sep 17 00:00:00 2001
From: Masahito S <firelzrd@gmail.com>
Date: Fri, 29 Dec 2023 10:16:46 +0900
Subject: [PATCH] lru_gen-oom-detection-fix-3

---
 mm/vmscan.c | 51 +++++++++++++++++++++++----------------------------
 1 file changed, 23 insertions(+), 28 deletions(-)

diff --git a/mm/vmscan.c b/mm/vmscan.c
index dcc264d3c9..892a67c632 100644
--- a/mm/vmscan.c
+++ b/mm/vmscan.c
@@ -4597,43 +4597,41 @@ static bool lruvec_is_reclaimable(struct lruvec *lruvec, struct scan_control *sc
 /* to protect the working set of the last N jiffies */
 static unsigned long lru_gen_min_ttl __read_mostly;
 
-static void lru_gen_age_node(struct pglist_data *pgdat, struct scan_control *sc)
-{
+static void invoke_oom(struct scan_control *sc) {
+	struct oom_control oc = {
+		.gfp_mask = sc->gfp_mask,
+		.order = sc->order,
+	};
+
+	if (mem_cgroup_oom_synchronize(true))
+		return;
+
+	if (!mutex_trylock(&oom_lock))
+		return;
+	out_of_memory(&oc);
+	mutex_unlock(&oom_lock);
+}
+
+static bool lru_gen_node_reclaimable(
+	struct pglist_data *pgdat, struct scan_control *sc) {
 	struct mem_cgroup *memcg;
 	unsigned long min_ttl = READ_ONCE(lru_gen_min_ttl);
 
 	VM_WARN_ON_ONCE(!current_is_kswapd());
 
-	/* check the order to exclude compaction-induced reclaim */
-	if (!min_ttl || sc->order || sc->priority == DEF_PRIORITY)
-		return;
-
 	memcg = mem_cgroup_iter(NULL, NULL, NULL);
 	do {
 		struct lruvec *lruvec = mem_cgroup_lruvec(memcg, pgdat);
 
 		if (lruvec_is_reclaimable(lruvec, sc, min_ttl)) {
 			mem_cgroup_iter_break(NULL, memcg);
-			return;
+			return true;
 		}
 
 		cond_resched();
 	} while ((memcg = mem_cgroup_iter(NULL, memcg, NULL)));
 
-	/*
-	 * The main goal is to OOM kill if every generation from all memcgs is
-	 * younger than min_ttl. However, another possibility is all memcgs are
-	 * either too small or below min.
-	 */
-	if (mutex_trylock(&oom_lock)) {
-		struct oom_control oc = {
-			.gfp_mask = sc->gfp_mask,
-		};
-
-		out_of_memory(&oc);
-
-		mutex_unlock(&oom_lock);
-	}
+	return false;
 }
 
 /******************************************************************************
@@ -5621,6 +5619,9 @@ static void lru_gen_shrink_node(struct pglist_data *pgdat, struct scan_control *
 	clear_mm_walk();
 
 	blk_finish_plug(&plug);
+
+	if (sc->nr_reclaimed == reclaimed && !lru_gen_node_reclaimable(pgdat, sc))
+		invoke_oom(sc);
 done:
 	/* kswapd should never fail */
 	pgdat->kswapd_failures = 0;
@@ -6286,10 +6287,6 @@ late_initcall(init_lru_gen);
 
 #else /* !CONFIG_LRU_GEN */
 
-static void lru_gen_age_node(struct pglist_data *pgdat, struct scan_control *sc)
-{
-}
-
 static void lru_gen_shrink_lruvec(struct lruvec *lruvec, struct scan_control *sc)
 {
 }
@@ -7198,10 +7195,8 @@ static void kswapd_age_node(struct pglist_data *pgdat, struct scan_control *sc)
 	struct mem_cgroup *memcg;
 	struct lruvec *lruvec;
 
-	if (lru_gen_enabled()) {
-		lru_gen_age_node(pgdat, sc);
+	if (lru_gen_enabled())
 		return;
-	}
 
 	if (!can_age_anon_pages(pgdat, sc))
 		return;
-- 
2.25.1

